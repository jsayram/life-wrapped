# Life Wrapped

> **Privacy-focused audio journaling for iOS, watchOS, and macOS.**

[![Swift 6.2](https://img.shields.io/badge/Swift-6.2-orange.svg)](https://swift.org)
[![Xcode 26](https://img.shields.io/badge/Xcode-26-blue.svg)](https://developer.apple.com/xcode/)
[![Platform](https://img.shields.io/badge/Platform-iOS%2018%20%7C%20watchOS%2011%20%7C%20macOS%2015-lightgrey.svg)](https://developer.apple.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ¯ What is Life Wrapped?

Life Wrapped records audio throughout your day, transcribes it **locally on your device**, and helps you discover insights about how you spend your time.

### Key Features

- ğŸ™ï¸ **Auto-Chunking Recording** â€” Automatically splits recordings into 30-300s chunks for efficient processing
- ğŸ—£ï¸ **On-Device Transcription** â€” Apple's Speech framework with abandoned utterance detection, no cloud required
- ğŸ¤– **Multi-Tier AI Summaries** â€” Intelligent fallback system with 4 engines:
  - **External API** (Best Quality) â€” GPT-4, Claude Sonnet 3.5 with your API keys
  - **Local AI** (Privacy-First) â€” Phi-3.5 Mini on-device via MLX, ~2.1GB model
  - **Apple Intelligence** (iOS 18.1+) â€” Foundation Models when available
  - **Basic** (Always Available) â€” Fast extractive summarization with NLP
- ğŸ”„ **Smart Fallback** â€” Automatically downgrades: External â†’ Local â†’ Apple â†’ Basic
- ğŸ“´ **Fully Offline Capable** â€” All features work without internet (Basic + Local AI)
- ğŸ“Š **Rich Insights** â€” Session summaries, topics, entities, sentiment, key moments
- âŒš **Apple Watch Support** â€” Control and glance from your wrist
- ğŸ”’ **Privacy-First** â€” Transcription always on-device; you control AI provider
- ğŸ“± **Widgets & Siri** â€” Quick stats and voice control

### How It Works

```
Record Audio â†’ Auto-Chunk (30-300s) â†’ Transcribe (On-Device) â†’ AI Summary
    â†“              â†“                       â†“                      â†“
Session ID    Chunk 0,1,2...        Apple Speech API      External/Local/Basic
    â†“              â†“                       â†“                      â†“
Database      Parallel Processing    Word-perfect text    Structured insights
```

**Audio Processing:**

- Recording automatically splits into configurable chunks (default 180s)
- Each chunk processes independently with parallel transcription (max 3 concurrent)
- Abandoned utterance detection captures pauses of any length
- Real-time UI updates show transcription progress per chunk

**AI Summarization (4-Tier System):**

1. **External API** (Cloud) â€” OpenAI GPT-4.1, Anthropic Claude 3.5 Sonnet
2. **Local AI** (On-Device) â€” Phi-3.5 Mini 4-bit quantized (~2.1GB via MLX)
3. **Apple Intelligence** (On-Device) â€” Foundation Models (iOS 18.1+, A17 Pro/M1+)
4. **Basic** (On-Device) â€” TF-IDF + semantic embeddings + NLP (always works)

---

## ğŸš€ Quick Start

### Prerequisites

- **Xcode 26.1+** (verify: `xcodebuild -version`)
- **Swift 6.2+** (verify: `swift --version`)
- **macOS Tahoe 26.0+** (verify: `sw_vers`)
- **Optional**: SwiftLint, swift-format (`brew install swiftlint swift-format`)

### Setup

```bash
# 1. Clone the repository
git clone https://github.com/jsayram/life-wrapped.git
cd life-wrapped

# 2. Copy secrets template
cp Config/Secrets.example.xcconfig Config/Secrets.xcconfig
# Edit Config/Secrets.xcconfig with your values

# 3. Make scripts executable
chmod +x Scripts/*.sh

# 4. Build packages (verify setup)
./Scripts/build.sh packages

# 5. Open in Xcode
open LifeWrapped.xcworkspace
```

---

## ğŸ› ï¸ Development Workflow

### VS Code + Xcode Hybrid

1. **Edit code in VS Code** â€” Swift LSP provides autocomplete
2. **Build/test via CLI** â€” `./Scripts/build.sh` and `./Scripts/test.sh`
3. **Run/debug in Xcode** â€” For device testing and Instruments

### Recommended VS Code Extensions

```bash
# Install recommended extensions
code --install-extension sswg.swift-lang
code --install-extension vknabel.vscode-apple-swift-format
```

### Scripts

| Script                        | Purpose                                 |
| ----------------------------- | --------------------------------------- |
| `./Scripts/build.sh [target]` | Build iOS, Watch, Widgets, or all       |
| `./Scripts/test.sh [target]`  | Run unit, integration, UI, or all tests |
| `./Scripts/lint.sh`           | Check code style                        |
| `./Scripts/format.sh`         | Auto-format Swift code                  |
| `./Scripts/verify-privacy.sh` | Verify no unauthorized network calls    |

---

## ğŸ“ Project Structure

```
life-wrapped/
â”œâ”€â”€ App/                 # iOS SwiftUI app
â”‚   â”œâ”€â”€ LifeWrappedApp.swift         # App entry point
â”‚   â”œâ”€â”€ ContentView.swift            # Main tab container
â”‚   â”œâ”€â”€ Coordinators/                # Business logic coordinators
â”‚   â”‚   â”œâ”€â”€ AppCoordinator.swift           # Central app coordinator
â”‚   â”‚   â”œâ”€â”€ RecordingCoordinator.swift     # Recording lifecycle
â”‚   â”‚   â”œâ”€â”€ TranscriptionCoordinator.swift # Transcription orchestration
â”‚   â”‚   â”œâ”€â”€ SummaryCoordinator.swift       # AI summary generation
â”‚   â”‚   â”œâ”€â”€ DataCoordinator.swift          # Data management operations
â”‚   â”‚   â”œâ”€â”€ WidgetCoordinator.swift        # Widget data updates
â”‚   â”‚   â”œâ”€â”€ PermissionsCoordinator.swift   # System permissions
â”‚   â”‚   â””â”€â”€ LocalModelCoordinator.swift    # Local LLM management
â”‚   â”œâ”€â”€ Views/                       # SwiftUI views
â”‚   â”‚   â”œâ”€â”€ Tabs/                    # Main tab views
â”‚   â”‚   â”œâ”€â”€ Overview/                # Overview & summaries
â”‚   â”‚   â”œâ”€â”€ Details/                 # Session detail views
â”‚   â”‚   â”œâ”€â”€ Insights/                # Analytics & charts
â”‚   â”‚   â”œâ”€â”€ AI/                      # AI settings & management
â”‚   â”‚   â”œâ”€â”€ Components/              # Reusable UI components
â”‚   â”‚   â””â”€â”€ Utility/                 # Helper views
â”‚   â”œâ”€â”€ Constants/                   # App-wide constants
â”‚   â”œâ”€â”€ Helpers/                     # Utility functions
â”‚   â”œâ”€â”€ Models/                      # View models
â”‚   â””â”€â”€ Resources/                   # Assets & entitlements
â”œâ”€â”€ Extensions/
â”‚   â””â”€â”€ Widgets/         # WidgetKit extension
â”œâ”€â”€ WatchApp/            # watchOS app
â”œâ”€â”€ Packages/            # Local Swift Packages
â”‚   â”œâ”€â”€ SharedModels/    # Data models & protocols
â”‚   â”œâ”€â”€ Storage/         # SQLite persistence with repository pattern
â”‚   â”‚   â”œâ”€â”€ DatabaseManager.swift          # Facade coordinating repositories
â”‚   â”‚   â”œâ”€â”€ DatabaseConnection.swift       # SQLite connection management
â”‚   â”‚   â”œâ”€â”€ SchemaManager.swift            # Schema versioning & migrations
â”‚   â”‚   â””â”€â”€ Repositories/
â”‚   â”‚       â”œâ”€â”€ AudioChunkRepository.swift      # Audio chunk CRUD
â”‚   â”‚       â”œâ”€â”€ SessionRepository.swift         # Recording session operations
â”‚   â”‚       â”œâ”€â”€ TranscriptRepository.swift      # Transcript segment storage
â”‚   â”‚       â”œâ”€â”€ SummaryRepository.swift         # AI summary management
â”‚   â”‚       â”œâ”€â”€ InsightsRepository.swift        # Stats & rollup queries
â”‚   â”‚       â””â”€â”€ ControlEventRepository.swift    # App control events
â”‚   â”œâ”€â”€ AudioCapture/    # AVAudioEngine recording & playback
â”‚   â”œâ”€â”€ Transcription/   # Apple Speech framework integration
â”‚   â”œâ”€â”€ InsightsRollup/  # Time-based aggregations & statistics
â”‚   â”œâ”€â”€ Summarization/   # External AI API adapter (OpenAI/Anthropic)
â”‚   â”œâ”€â”€ LocalLLM/        # On-device MLX-based language models
â”‚   â””â”€â”€ WidgetCore/      # Shared widget data models
â”œâ”€â”€ Config/              # Build configurations (.xcconfig)
â”œâ”€â”€ Scripts/             # Build/test automation scripts
â”œâ”€â”€ Docs/                # Documentation
â””â”€â”€ Tests/               # Test suites
â””â”€â”€ Tests/               # Test suites
```

---

## ğŸ”’ Privacy & Security

### Our Commitments

1. **On-Device Transcription** â€” All speech-to-text processing happens locally using `requiresOnDeviceRecognition = true`
2. **No Cloud Speech** â€” Apple Speech Recognition with strict on-device enforcement
3. **Privacy-First AI Options** â€” Multiple on-device engines available:
   - **Basic Engine** â€” NaturalLanguage framework, no data leaves device
   - **Local AI** â€” Phi-3.5 Mini runs entirely on your device via MLX (~2.1GB)
   - **Apple Intelligence** â€” On-device Foundation Models (iOS 18.1+, when available)
4. **Optional External AI** â€” Use your own API keys (OpenAI/Anthropic) only if you choose
5. **Smart Fallback Chain** â€” Automatic downgrade: External â†’ Local â†’ Apple â†’ Basic
6. **No Analytics** â€” No tracking, no telemetry, no third-party SDKs
7. **Encrypted Storage** â€” SQLite with file protection, App Group sandboxing
8. **Your Data, Your Control** â€” Export anytime, delete anytime

### AI Engine Details

**External API (Optional):**

- Providers: OpenAI (GPT-4.1, GPT-4o-mini) or Anthropic (Claude 3.5 Sonnet/Haiku)
- Requires: Your API key stored securely in Keychain
- Privacy: Sends transcript text to provider's servers (your keys, your control)
- Quality: Highest quality summaries with structured insights

**Local AI (On-Device):**

- Model: Phi-3.5 Mini 4-bit quantized (Microsoft)
- Size: ~2.1 GB download via HuggingFace
- Framework: MLX (Apple's ML framework for Apple Silicon)
- Privacy: 100% on-device, no internet required
- Performance: Smart caching, chunk-by-chunk processing

**Apple Intelligence (On-Device, iOS 18.1+):**

- Availability: A17 Pro+ / M1+ with Apple Intelligence enabled
- Privacy: On-device Foundation Models
- Status: Placeholder for future integration

**Basic Engine (Always Available):**

- Framework: Apple's NaturalLanguage with TF-IDF + embeddings
- Features: Extractive summarization, keyword extraction, sentiment analysis
- Privacy: 100% on-device, instant processing
- Use Case: Fallback when other engines unavailable

### Verification

```bash
# Run privacy audit (checks for unauthorized network calls)
./Scripts/verify-privacy.sh

# Manual verification:
# 1. Without API keys â€” app uses Local AI or Basic engine (fully offline)
# 2. Network offline â€” Local AI and Basic engines work perfectly
# 3. With API keys â€” only external AI API calls are made (optional, you control)
```

---

## ğŸ§ª Testing

```bash
# Run all tests
./Scripts/test.sh all

# Package tests only (fast)
./Scripts/test.sh packages

# With coverage
xcodebuild test \
  -workspace LifeWrapped.xcworkspace \
  -scheme LifeWrappedTests \
  -destination 'platform=iOS Simulator,name=iPhone 16 Pro' \
  -enableCodeCoverage YES
```

### Test Categories

- **Unit Tests** â€” Package-level logic (Storage, Insights, Backup)
- **Integration Tests** â€” Cross-package flows (Audio â†’ Transcribe â†’ Store)
- **UI Tests** â€” User interaction flows
- **Performance Tests** â€” XCTest metrics + Instruments

---

## ğŸ“š Documentation

- [WORKFLOW.md](Docs/WORKFLOW.md) â€” Complete development workflow
- [ARCHITECTURE.md](Docs/ARCHITECTURE.md) â€” System design (coming)
- [DATA_MODEL.md](Docs/DATA_MODEL.md) â€” SQLite schema (coming)
- [PRIVACY.md](Docs/PRIVACY.md) â€” Privacy implementation (coming)
- [TESTING.md](Docs/TESTING.md) â€” Test strategy (coming)

---

## ğŸ—ºï¸ Roadmap

### V1 (Current) âœ…

- [x] Project setup & architecture
- [x] SQLite storage with repository pattern
- [x] Auto-chunking audio capture pipeline
- [x] On-device transcription (Apple Speech)
- [x] Multi-tier AI summarization (4 engines)
- [x] Local LLM (Phi-3.5 Mini via MLX)
- [x] Insights & time-based rollups
- [x] iOS widgets
- [x] Apple Watch app (in progress)

### V2 (Future)

- [ ] CloudKit sync (opt-in)
- [ ] Siri Shortcuts integration
- [ ] macOS companion app
- [ ] Speaker diarization
- [ ] Advanced entity extraction
- [ ] Export/backup system

---

## ğŸ¤ Contributing

This is a personal project, but suggestions are welcome! Please open an issue to discuss changes.

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- Apple's Speech framework for on-device transcription
- GRDB.swift for SQLite (if used)
- The Swift community for excellent tooling

---

**Built with â¤ï¸ and ğŸ”’ privacy in mind.**
